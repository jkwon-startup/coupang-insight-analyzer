"""E-Commerce Insight Analyzer - í´ë¼ìš°ë“œ ë°°í¬ìš© (headless Chromium)

Streamlit Community Cloudì—ì„œ ë™ì‘í•˜ëŠ” ë²„ì „.
ë¡œì»¬ GUI ë²„ì „ì€ app.py ì°¸ì¡°.

ì°¨ì´ì :
- headless Chromium ì‚¬ìš© (Chrome ì°½ì´ ì—´ë¦¬ì§€ ì•ŠìŒ)
- CAPTCHA ë°œìƒ ì‹œ ì•ˆë‚´ ë©”ì‹œì§€ í‘œì‹œ í›„ ì¤‘ë‹¨
"""

import asyncio
import json
import streamlit as st

from utils.validators import validate_product_url, detect_platform, validate_api_key
from crawler.url_parser import parse_url
from crawler.browser_cloud import CoupangBrowserCloud, NaverBrowserCloud
from crawler.product_page import ProductPageScraper
from crawler.review_scraper import ReviewScraper
from crawler.qna_scraper import QnAScraper
from crawler.naver_product_page import NaverProductPageScraper
from crawler.naver_review_scraper import NaverReviewScraper
from crawler.naver_qna_scraper import NaverQnAScraper
from analyzer.ai_client import create_ai_client
from analyzer.story_analyzer import StoryAnalyzer
from analyzer.review_analyzer import ReviewAnalyzer
from analyzer.qna_analyzer import QnAAnalyzer
from analyzer.full_report import FullReportAnalyzer
from exporter.excel_exporter import ExcelExporter
from exporter.word_exporter import WordExporter

st.set_page_config(
    page_title="E-Commerce Insight Analyzer",
    page_icon="ğŸ”",
    layout="wide",
)

st.markdown("""
<style>
    .main-title { font-size: 2rem; font-weight: 700; margin-bottom: 0.5rem; }
    .sub-title { color: #666; font-size: 1rem; margin-bottom: 2rem; }
    .stButton > button[kind="primary"] { width: 100%; }
    .platform-badge {
        display: inline-block;
        padding: 4px 12px;
        border-radius: 12px;
        font-weight: 600;
        font-size: 0.85rem;
        margin-left: 8px;
    }
    .badge-coupang { background: #FF6B35; color: white; }
    .badge-naver { background: #03C75A; color: white; }
    .cloud-badge {
        display: inline-block;
        padding: 2px 8px;
        border-radius: 8px;
        background: #6C63FF;
        color: white;
        font-size: 0.75rem;
        margin-left: 8px;
    }
</style>
""", unsafe_allow_html=True)


def main():
    st.markdown(
        '<div class="main-title">E-Commerce Insight Analyzer '
        '<span class="cloud-badge">Cloud</span></div>',
        unsafe_allow_html=True,
    )
    st.markdown(
        '<div class="sub-title">'
        'ì¿ íŒ¡ ë˜ëŠ” ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆ ë§í¬ë¥¼ ì…ë ¥í•˜ë©´ ìƒì„¸í˜ì´ì§€, ë¦¬ë·°, Q&Aë¥¼ ìë™ ë¶„ì„í•©ë‹ˆë‹¤'
        '</div>',
        unsafe_allow_html=True,
    )

    # í´ë¼ìš°ë“œ ì•ˆë‚´
    with st.expander("Cloud ë²„ì „ ì•ˆë‚´", expanded=False):
        st.info(
            "**Cloud ë²„ì „ ì œí•œì‚¬í•­:**\n"
            "- ë´‡ íƒì§€(CAPTCHA)ê°€ ë°œìƒí•˜ë©´ í•´ë‹¹ ìƒí’ˆì˜ ë°ì´í„° ìˆ˜ì§‘ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n"
            "- CAPTCHA ì—†ì´ ì ‘ì†ë˜ëŠ” ìƒí’ˆì€ ì •ìƒì ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤\n\n"
            "**ë¡œì»¬ ë²„ì „ (ì œí•œ ì—†ìŒ):**\n"
            "- GitHubì—ì„œ ì½”ë“œë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ë©´ CAPTCHAë¥¼ ì§ì ‘ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n"
            "- `git clone` â†’ `pip install -r requirements.txt` â†’ `streamlit run app.py`"
        )

    url = st.text_input(
        "ìƒí’ˆ URL",
        placeholder="ì¿ íŒ¡ ë˜ëŠ” ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ URLì„ ì…ë ¥í•˜ì„¸ìš”",
    )

    if url and url.strip():
        platform = detect_platform(url)
        if platform == "coupang":
            st.markdown(
                '<span class="platform-badge badge-coupang">ì¿ íŒ¡</span> ìƒí’ˆì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.',
                unsafe_allow_html=True,
            )
        elif platform == "naver":
            st.markdown(
                '<span class="platform-badge badge-naver">ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´</span> ìƒí’ˆì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.',
                unsafe_allow_html=True,
            )
        else:
            st.warning("ì§€ì›í•˜ì§€ ì•ŠëŠ” URLì…ë‹ˆë‹¤. ì¿ íŒ¡ ë˜ëŠ” ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.subheader("AI ëª¨ë¸ ì„ íƒ")
    col1, col2 = st.columns(2)
    with col1:
        use_claude = st.checkbox("Anthropic Claude", value=True)
    with col2:
        use_openai = st.checkbox("OpenAI o4-mini", value=False)

    if use_claude:
        claude_key = st.text_input("Anthropic API Key", type="password")
    if use_openai:
        openai_key = st.text_input("OpenAI API Key", type="password")

    st.subheader("ë¶„ì„ ì˜µì…˜")
    col_a, col_b, col_c, col_d = st.columns(4)
    with col_a:
        do_story = st.checkbox("ìƒì„¸í˜ì´ì§€ ìŠ¤í† ë¦¬ ë¶„ì„", value=True)
    with col_b:
        do_review = st.checkbox("ë¦¬ë·° ë¶„ì„", value=True)
    with col_c:
        do_qna = st.checkbox("ìƒí’ˆë¬¸ì˜ ë¶„ì„", value=True)
    with col_d:
        do_full = st.checkbox("ì „ì²´ í†µí•© ë¶„ì„", value=True)

    if st.button("ë¶„ì„ ì‹œì‘", type="primary"):
        url_valid, url_msg, platform = validate_product_url(url)
        if not url_valid:
            st.error(url_msg)
            return

        if not use_openai and not use_claude:
            st.error("ìµœì†Œ í•˜ë‚˜ì˜ AI ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        if use_claude:
            key_valid, key_msg = validate_api_key(claude_key, "claude")
            if not key_valid:
                st.error(f"Claude: {key_msg}")
                return

        if use_openai:
            key_valid, key_msg = validate_api_key(openai_key, "openai")
            if not key_valid:
                st.error(f"OpenAI: {key_msg}")
                return

        if not any([do_story, do_review, do_qna, do_full]):
            st.error("ìµœì†Œ í•˜ë‚˜ì˜ ë¶„ì„ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        ai_configs = []
        if use_claude:
            ai_configs.append(("claude", claude_key, "Anthropic Claude"))
        if use_openai:
            ai_configs.append(("openai", openai_key, "OpenAI o4-mini"))

        run_analysis(url, platform, ai_configs, do_story, do_review, do_qna, do_full)

    st.divider()
    st.warning(
        "ë³¸ ì„œë¹„ìŠ¤ëŠ” ëª¨ë“  ë¶„ì„ ê¸°ë¡ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
        "ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìš´ë¡œë“œ ë°›ìœ¼ì„¸ìš”. "
        "í˜ì´ì§€ë¥¼ ë²—ì–´ë‚˜ë©´ ê²°ê³¼ëŠ” ì‚­ì œë©ë‹ˆë‹¤."
    )


def run_analysis(url, platform, ai_configs, do_story, do_review, do_qna, do_full):
    """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (í´ë¼ìš°ë“œ headless ëª¨ë“œ)"""
    try:
        product_info = parse_url(url, platform)
    except ValueError as e:
        st.error(str(e))
        return

    progress = st.progress(0, text="ì¤€ë¹„ ì¤‘...")
    status = st.empty()

    product_data = None
    reviews = []
    qna_pairs = []

    try:
        status.info("í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        progress.progress(5, text="ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...")

        if platform == "coupang":
            crawl_fn = _make_coupang_crawl(
                product_info, do_story, do_review, do_qna, do_full, progress, status
            )
        else:
            crawl_fn = _make_naver_crawl(
                product_info, do_story, do_review, do_qna, do_full, progress, status
            )

        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as pool:
                    result = pool.submit(asyncio.run, crawl_fn()).result()
            else:
                result = loop.run_until_complete(crawl_fn())
        except RuntimeError:
            result = asyncio.run(crawl_fn())

        if result is None:
            return

        product_data, reviews, qna_pairs = result

        # AI ë¶„ì„
        all_results = {}

        for idx, (provider, api_key, label) in enumerate(ai_configs):
            progress.progress(50, text=f"{label} ë¶„ì„ ì‹œì‘...")
            ai_client = create_ai_client(provider, api_key)

            story_result = ""
            review_result = ""
            qna_result = ""
            full_result = ""

            if do_story and product_data:
                progress.progress(55, text=f"[{label}] ìƒì„¸í˜ì´ì§€ ìŠ¤í† ë¦¬ ë¶„ì„ ì¤‘...")
                analyzer = StoryAnalyzer(ai_client)
                story_result = analyzer.analyze(product_data)

            if do_review and reviews:
                progress.progress(65, text=f"[{label}] ë¦¬ë·° ë¶„ì„ ì¤‘...")
                analyzer = ReviewAnalyzer(ai_client)
                review_result = analyzer.analyze(reviews)

            if do_qna and qna_pairs:
                progress.progress(75, text=f"[{label}] Q&A ë¶„ì„ ì¤‘...")
                analyzer = QnAAnalyzer(ai_client)
                qna_result = analyzer.analyze(qna_pairs)

            if do_full and (story_result or review_result or qna_result):
                progress.progress(85, text=f"[{label}] ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
                analyzer = FullReportAnalyzer(ai_client)
                full_result = analyzer.analyze(
                    product_data, story_result, review_result, qna_result
                )

            all_results[label] = {
                "story": story_result,
                "review": review_result,
                "qna": qna_result,
                "full": full_result,
            }

        progress.progress(95, text="ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        progress.progress(100, text="ë¶„ì„ ì™„ë£Œ!")
        status.success("ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        for label, res in all_results.items():
            display_results(
                label, product_data, reviews, qna_pairs, res,
                do_story, do_review, do_qna, do_full,
            )
            create_downloads(
                label, platform, product_data, reviews, qna_pairs, res,
            )

    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        progress.empty()


def _make_coupang_crawl(product_info, do_story, do_review, do_qna, do_full, progress, status):
    async def crawl():
        product_data = None
        reviews = []
        qna_pairs = []

        browser = CoupangBrowserCloud()
        try:
            await browser.launch()
            progress.progress(10, text="ì¿ íŒ¡ ìƒí’ˆ í˜ì´ì§€ ì ‘ì† ì¤‘...")

            success = await browser.navigate(product_info["full_url"])
            if not success:
                st.error(
                    "ì¿ íŒ¡ í˜ì´ì§€ ì ‘ì†ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ë´‡ ì°¨ë‹¨)\n\n"
                    "ì¿ íŒ¡ì€ ë´‡ íƒì§€ê°€ ê°•ë ¥í•˜ì—¬ Cloud í™˜ê²½ì—ì„œ ì°¨ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                    "ë¡œì»¬ ë²„ì „(`streamlit run app.py`)ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”."
                )
                return None

            if do_story or do_full:
                progress.progress(15, text="ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
                scraper = ProductPageScraper()
                product_data = await scraper.scrape(browser.page, product_info)

            if do_review or do_full:
                progress.progress(20, text="ë¦¬ë·° ìˆ˜ì§‘ ì¤‘...")
                review_scraper = ReviewScraper()
                reviews = await review_scraper.scrape_all(
                    browser, product_info,
                    lambda msg, pct: progress.progress(20 + int(pct * 0.25), text=msg),
                )
                status.success(_review_summary(reviews))

            if do_qna or do_full:
                progress.progress(45, text="Q&A ìˆ˜ì§‘ ì¤‘...")
                qna_scraper = QnAScraper()
                qna_pairs = await qna_scraper.scrape(
                    browser.page, lambda msg: status.info(msg),
                )
                status.success(_qna_summary(qna_pairs))

            return (product_data, reviews, qna_pairs)
        finally:
            await browser.close()

    return crawl


def _make_naver_crawl(product_info, do_story, do_review, do_qna, do_full, progress, status):
    async def crawl():
        product_data = None
        reviews = []
        qna_pairs = []

        browser = NaverBrowserCloud()
        try:
            await browser.launch()
            progress.progress(10, text="ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì ‘ì† ì¤‘...")
            browser.set_status_callback(lambda msg: status.info(msg))

            success = await browser.navigate_with_mobile_fallback(
                product_info["desktop_url"],
                product_info["mobile_url"],
            )

            # CAPTCHA ê°ì§€ ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
            if not success and browser.captcha_detected:
                st.warning(
                    "**ë´‡ íƒì§€(CAPTCHA)ê°€ ë°œìƒí•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤.**\n\n"
                    "ë„¤ì´ë²„ì—ì„œ ìë™ ì ‘ì†ì„ ì°¨ë‹¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë°©ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”:\n"
                    "- ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš” (ë³´í†µ ëª‡ ë¶„ í›„ í•´ì œë©ë‹ˆë‹¤)\n"
                    "- ë‹¤ë¥¸ ìƒí’ˆ URLë¡œ ì‹œë„í•´ë³´ì„¸ìš”\n"
                    "- **ë¡œì»¬ ë²„ì „**ì—ì„œëŠ” CAPTCHAë¥¼ ì§ì ‘ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤: "
                    "`streamlit run app.py`"
                )
                return None

            if not success:
                st.error(
                    "ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì ‘ì†ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
                    "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ë‹¤ë¥¸ ìƒí’ˆ URLì„ ì‚¬ìš©í•´ë³´ì„¸ìš”."
                )
                return None

            progress.progress(12, text="í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            next_data = await browser.extract_page_data_json()
            if next_data:
                status.info("í˜ì´ì§€ JSON ë°ì´í„° ì¶”ì¶œ ì„±ê³µ!")
            else:
                status.info("JSON ë°ì´í„° ì—†ìŒ â€” DOM ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤")

            if do_story or do_full:
                progress.progress(15, text="ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
                scraper = NaverProductPageScraper()
                product_data = await scraper.scrape(browser.page, product_info, next_data)

            if do_review or do_full:
                progress.progress(20, text="ë¦¬ë·° ìˆ˜ì§‘ ì¤‘...")
                review_scraper = NaverReviewScraper()
                reviews = await review_scraper.scrape_all(
                    browser, product_info, next_data,
                    lambda msg, pct: progress.progress(20 + int(pct * 0.25), text=msg),
                )
                status.success(_review_summary(reviews))

            if do_qna or do_full:
                progress.progress(45, text="Q&A ìˆ˜ì§‘ ì¤‘...")
                qna_scraper = NaverQnAScraper()
                qna_pairs = await qna_scraper.scrape(
                    browser, product_info, next_data,
                    lambda msg: status.info(msg),
                )
                status.success(_qna_summary(qna_pairs))

            return (product_data, reviews, qna_pairs)
        finally:
            await browser.close()

    return crawl


def _review_summary(reviews: list) -> str:
    """ë¦¬ë·° ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ë¬¸ìì—´ ìƒì„±."""
    if not reviews:
        return "ë¦¬ë·° 0ê±´ ìˆ˜ì§‘"
    total = len(reviews)
    rating_counts = {}
    for r in reviews:
        score = r.get("rating")
        if score is not None:
            key = int(round(float(score)))
            rating_counts[key] = rating_counts.get(key, 0) + 1
    parts = [f"ë¦¬ë·° {total}ê±´ ìˆ˜ì§‘"]
    rating_strs = []
    for star in (5, 4, 3, 2, 1):
        cnt = rating_counts.get(star, 0)
        if cnt > 0:
            rating_strs.append(f"{star}ì : {cnt}ê±´")
    if rating_strs:
        parts.append(f"({' / '.join(rating_strs)})")
    return " ".join(parts)


def _qna_summary(qna_pairs: list) -> str:
    """Q&A ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ë¬¸ìì—´ ìƒì„±."""
    if not qna_pairs:
        return "ìƒí’ˆ ë¬¸ì˜ 0ê±´ ìˆ˜ì§‘"
    total = len(qna_pairs)
    secret = sum(
        1 for p in qna_pairs
        if "(ë¹„ê³µê°œ" in p.get("question", "") or "ë¹„ë°€ê¸€" in p.get("question", "")
    )
    answered = sum(
        1 for p in qna_pairs
        if p.get("answer", "") and p.get("answer", "") not in ("", "(ë‹µë³€ì™„ë£Œ)")
    )
    parts = [f"ì „ì²´ ìƒí’ˆ ë¬¸ì˜ {total}ê±´"]
    if secret > 0:
        parts.append(f"ë¹„ë°€ê¸€ {secret}ê±´")
    parts.append(f"í™•ì¸ë‹µë³€ {answered}ê±´")
    return ", ".join(parts)


def display_results(label, product_data, reviews, qna_pairs, res, do_story, do_review, do_qna, do_full):
    st.divider()
    st.subheader(f"ë¶„ì„ ê²°ê³¼ - {label}")

    if do_story and res["story"]:
        with st.expander("ìƒì„¸í˜ì´ì§€ ìŠ¤í† ë¦¬ ë¶„ì„", expanded=True):
            st.markdown(res["story"])

    if do_review and res["review"]:
        with st.expander("ë¦¬ë·° ë¶„ì„", expanded=True):
            st.markdown(res["review"])
            if reviews:
                st.caption(_review_summary(reviews))

    if do_qna and res["qna"]:
        with st.expander("ìƒí’ˆë¬¸ì˜(Q&A) ë¶„ì„", expanded=True):
            st.markdown(res["qna"])
            if qna_pairs:
                st.caption(_qna_summary(qna_pairs))

    if do_full and res["full"]:
        with st.expander("ì¢…í•© ë¦¬í¬íŠ¸", expanded=True):
            st.markdown(res["full"])


def create_downloads(label, platform, product_data, reviews, qna_pairs, res):
    st.divider()
    st.subheader(f"ë‹¤ìš´ë¡œë“œ - {label}")

    safe_label = label.replace(" ", "_").lower()
    prefix = f"{platform}_analysis"
    col1, col2, col3 = st.columns(3)

    with col1:
        try:
            exporter = ExcelExporter()
            excel_bytes = exporter.generate(
                product_data, reviews, qna_pairs,
                res["story"], res["review"], res["qna"], res["full"],
            )
            st.download_button(
                label="Excel (.xlsx)", data=excel_bytes,
                file_name=f"{prefix}_{safe_label}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"excel_{safe_label}",
            )
        except Exception as e:
            st.error(f"Excel ìƒì„± ì‹¤íŒ¨: {e}")

    with col2:
        try:
            exporter = WordExporter()
            word_bytes = exporter.generate(
                product_data, res["story"], res["review"], res["qna"], res["full"],
            )
            st.download_button(
                label="Word (.docx)", data=word_bytes,
                file_name=f"{prefix}_{safe_label}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                key=f"word_{safe_label}",
            )
        except Exception as e:
            st.error(f"Word ìƒì„± ì‹¤íŒ¨: {e}")

    with col3:
        raw_data = {
            "platform": platform, "reviews": reviews,
            "qna": qna_pairs, "product": product_data, "analysis": res,
        }
        st.download_button(
            label="ì›ë³¸ ë°ì´í„° (.json)",
            data=json.dumps(raw_data, ensure_ascii=False, indent=2),
            file_name=f"{prefix}_raw_{safe_label}.json",
            mime="application/json", key=f"json_{safe_label}",
        )


if __name__ == "__main__":
    main()
